{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/qp7fc0cadZ6piY71uCBS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArjavRD/RAG-Chatbot-for-Research-Papers/blob/main/Research_Paper_RAG_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Full RAG Chatbot with detailed comments\n",
        "\n",
        "# Step 1: Imports\n",
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import faiss\n",
        "import fitz  # PyMuPDF for PDF reading\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Step 2: Function to search arXiv using free API\n",
        "def search_arxiv(query, max_results=5):\n",
        "    url = f\"http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results={max_results}\"\n",
        "    response = requests.get(url)\n",
        "    root = ET.fromstring(response.text)\n",
        "    papers = []\n",
        "    for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):\n",
        "        title = entry.find('{http://www.w3.org/2005/Atom}title').text.strip()\n",
        "        summary = entry.find('{http://www.w3.org/2005/Atom}summary').text.strip()\n",
        "        link = entry.find('{http://www.w3.org/2005/Atom}id').text.strip()\n",
        "        papers.append({\"title\": title, \"summary\": summary, \"link\": link})\n",
        "    return papers\n",
        "\n",
        "# Step 3: Function to split long text into smaller chunks for processing\n",
        "def chunk_text(text, size=500):\n",
        "    return [text[i:i+size] for i in range(0, len(text), size)]\n",
        "\n",
        "# Step 4: Function to read a PDF file and return all the text\n",
        "def parse_pdf(file_path):\n",
        "    doc = fitz.open(file_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# Step 5: Function to get sentence embeddings from a model\n",
        "def get_embeddings(chunks, model):\n",
        "    return model.encode(chunks)\n",
        "\n",
        "# Step 6: Build a FAISS index for fast similarity search\n",
        "def build_faiss_index(embeddings):\n",
        "    dim = embeddings[0].shape[0]\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(np.array(embeddings))\n",
        "    return index\n",
        "\n",
        "# Step 7: Retrieve the top-k relevant chunks given a query\n",
        "def retrieve_top_chunks(query, chunks, index, model, top_k=3):\n",
        "    q_vec = model.encode([query])\n",
        "    D, I = index.search(np.array(q_vec), top_k)\n",
        "    return [chunks[i] for i in I[0]]\n",
        "\n",
        "# Step 8: Create a natural language prompt using retrieved context\n",
        "def create_prompt(context_chunks, user_question):\n",
        "    context = \"\\n\\n\".join(context_chunks)\n",
        "    return f\"Context:\\n{context}\\n\\nQuestion: {user_question}\\nAnswer:\"\n",
        "\n",
        "# Step 9: Print arXiv paper links for reference\n",
        "def show_links(papers):\n",
        "    print(\"\\nSources:\")\n",
        "    for p in papers:\n",
        "        print(f\"- {p['title']}\\n  {p['link']}\\n\")\n",
        "\n",
        "# Step 10: Main function that runs the chatbot\n",
        "def run_chatbot(query_topic, user_question, pdf_path=None):\n",
        "    print(\"Loading embedding model...\")\n",
        "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    # Fetch papers\n",
        "    print(f\"Searching arXiv for: {query_topic}\")\n",
        "    arxiv_papers = search_arxiv(query_topic, max_results=5)\n",
        "    arxiv_text = \" \".join([f\"{p['title']}: {p['summary']}\" for p in arxiv_papers])\n",
        "    arxiv_chunks = chunk_text(arxiv_text)\n",
        "\n",
        "    # Add optional PDF content\n",
        "    if pdf_path:\n",
        "        print(f\"Reading PDF: {pdf_path}\")\n",
        "        pdf_text = parse_pdf(pdf_path)\n",
        "        pdf_chunks = chunk_text(pdf_text)\n",
        "        all_chunks = arxiv_chunks + pdf_chunks\n",
        "    else:\n",
        "        all_chunks = arxiv_chunks\n",
        "\n",
        "    # Embedding + indexing\n",
        "    print(\"Generating embeddings and building vector index...\")\n",
        "    embeddings = get_embeddings(all_chunks, model)\n",
        "    index = build_faiss_index(embeddings)\n",
        "\n",
        "    # Retrieval\n",
        "    print(f\"Retrieving relevant context for: {user_question}\")\n",
        "    top_chunks = retrieve_top_chunks(user_question, all_chunks, index, model)\n",
        "    prompt = create_prompt(top_chunks, user_question)\n",
        "\n",
        "    # Output\n",
        "    print(\"\\n=== Prompt to send to an LLM ===\\n\")\n",
        "    print(prompt)\n",
        "    print(\"\\n=== Source Papers ===\")\n",
        "    show_links(arxiv_papers)\n",
        "\n",
        "# Ask user for input\n",
        "def main():\n",
        "    topic = input(\"Enter your topic of interest (e.g. graph neural networks): \")\n",
        "    question = input(\"Enter your question: \")\n",
        "    use_pdf = input(\"Do you want to include a PDF? (yes/no): \").lower()\n",
        "    pdf_path = None\n",
        "    if use_pdf == \"yes\":\n",
        "        pdf_path = input(\"Enter path to the PDF file: \")\n",
        "    run_chatbot(topic, question, pdf_path)\n",
        "\n",
        "# Run the chatbot interactively\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD34pw8CRJR7",
        "outputId": "948cdcdf-ed84-4be5-bffd-8d2e71e8c5c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your topic of interest (e.g. graph neural networks): stocks\n",
            "Enter your question: analysis given a dataset\n",
            "Do you want to include a PDF? (yes/no): no\n",
            "Loading embedding model...\n",
            "Searching arXiv for: stocks\n",
            "Generating embeddings and building vector index...\n",
            "Retrieving relevant context for: analysis given a dataset\n",
            "\n",
            "=== Prompt to send to an LLM ===\n",
            "\n",
            "Context:\n",
            "ks. In this paper, we simulate\n",
            "data-rich and data-poor fishery and survey data scenarios for a complex of\n",
            "dover sole stocks. Simulated data for individual stocks were used to compare\n",
            "estimation performance for single-stock and hierarchical multi-stock versions\n",
            "of a Schaefer production model. The single-stock and best performing\n",
            "multi-stock models were then used in stock assessments for the real dover sole\n",
            "data. Multi-stock models often had lower estimation errors than single-stock\n",
            "models when as\n",
            "\n",
            " targets at predicting\n",
            "stock prices, less effort is made for profitable stock recommendation. Besides,\n",
            "in existing approaches on modeling time series of stock prices, the\n",
            "relationships among stocks and sectors (i.e., categories of stocks) are either\n",
            "neglected or pre-defined. Ignoring stock relationships will miss the\n",
            "information shared between stocks while using pre-defined relationships cannot\n",
            "depict the latent interactions or influence of stock prices between stocks. In\n",
            "this work, we aim at re\n",
            "\n",
            "sessment data had low statistical power. Relative errors for\n",
            "productivity and relative biomass parameters were lower for multi-stock\n",
            "assessment model configurations. In addition, multi-stock models that estimated\n",
            "hierarchical priors for survey catchability performed the best under data-poor\n",
            "scenarios. We conclude that hierarchical multi-stock assessment models are\n",
            "useful for data-limited stocks and could provide a more flexible alternative to\n",
            "data-pooling and catch only methods; however, these m\n",
            "\n",
            "Question: analysis given a dataset\n",
            "Answer:\n",
            "\n",
            "=== Source Papers ===\n",
            "\n",
            "Sources:\n",
            "- MASTER: Market-Guided Stock Transformer for Stock Price Forecasting\n",
            "  http://arxiv.org/abs/2312.15235v1\n",
            "\n",
            "- Information flow between composite stock index and individual stocks\n",
            "  http://arxiv.org/abs/0708.0063v1\n",
            "\n",
            "- FinGAT: Financial Graph Attention Networks for Recommending Top-K\n",
            "  Profitable Stocks\n",
            "  http://arxiv.org/abs/2106.10159v1\n",
            "\n",
            "- Crossing Stocks and the Positive Grassmannian I: The Geometry behind\n",
            "  Stock Market\n",
            "  http://arxiv.org/abs/1402.1281v2\n",
            "\n",
            "- Evaluating the role of data quality when sharing information in\n",
            "  hierarchical multi-stock assessment models, with an application to Dover Sole\n",
            "  http://arxiv.org/abs/1804.03353v2\n",
            "\n"
          ]
        }
      ]
    }
  ]
}